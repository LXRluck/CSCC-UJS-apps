# import os,re
# import sys
# import time
# import tempfile
# from PySide6.QtCore import QObject, Signal
# from datetime import timedelta
# import whisper
# from opencc import OpenCC
# import subprocess
# from tqdm import tqdm
# from gui.core.api_utils.asr import ASRClient
# # å­—å¹•ç”Ÿæˆ
# # éŸ³é¢‘åˆ‡ç‰‡ï¼Œå¯ä»¥æ­£å¸¸è¯†åˆ«éŸ³é¢‘å¹¶è¾“å‡ºåˆ†ç‰‡å­—å¹•
# def clean_temp(files):
#     for file in files:
#         if os.path.exists(file):
#             try:
#                 os.remove(file)
#             except Exception as e:
#                 print(f"è­¦å‘Šï¼šæ— æ³•åˆ é™¤ä¸´æ—¶æ–‡ä»¶ {file}: {e}")

# class SubtitleWorker(QObject):
#     progress = Signal(str, int)
#     finished = Signal(bool, str)
#     subtitle_updated = Signal(float,float,str)  

#     def __init__(self,asr_client, video_path, srt_path,  total_duration, slice_duration=10, short_segment_threshold=2.0):
#         super().__init__()
#         self.asr_client=asr_client
#         self.video_path = video_path
#         self.srt_path = srt_path,
#         self.slice_duration = slice_duration  # åˆ‡ç‰‡æ—¶é•¿
#         self.short_segment_threshold = short_segment_threshold  # é˜ˆå€¼
#         self.is_running = True
#         self.converter = OpenCC('t2s')  
#         self.model = None  
#         self.subtitle_index = 1  
#         self.temp_files = []  
#         self.short_segments_cache = []  
#         self.total_duration=total_duration

#     def preload_model(self):
#         # """é¢„åŠ è½½Whisperæ¨¡å‹ï¼ˆé¿å…å®æ—¶è¯†åˆ«æ—¶å¡é¡¿ï¼‰"""
#         # self.progress.emit("æ­£åœ¨åŠ è½½è¯†åˆ«æ¨¡å‹...", 5)
#         # self.model = whisper.load_model(self.model_size)
#         # self.progress.emit("æ¨¡å‹åŠ è½½å®Œæˆ", 10)
#         """é¢„åŠ è½½API"""
#         self.progress.emit("æ­£åœ¨åŠ è½½è¯†åˆ«æ¨¡å‹...", 5)
#     def extract_audio_slice(self, start_time, duration, output_file):
#         cmd = [
#             'ffmpeg',
#             '-y',  # è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶
#             '-ss', f'{start_time:.2f}',  # èµ·å§‹æ—¶é—´
#             '-i', self.video_path,  # è¾“å…¥è§†é¢‘æ–‡ä»¶
#             '-t', f'{duration:.2f}',  # æå–æ—¶é•¿
#             '-vn',  # ç¦ç”¨è§†é¢‘æµ
#             '-acodec', 'pcm_s16le',  # éŸ³é¢‘ç¼–ç 
#             '-ar', '16000',  # é‡‡æ ·ç‡
#             '-ac', '1',  # å•å£°é“
#             '-f', 'wav',  # è¾“å‡ºæ ¼å¼
#             '-hide_banner',  # éšè—bannerä¿¡æ¯
#             '-loglevel', 'error',  # ä»…è¾“å‡ºé”™è¯¯ä¿¡æ¯
#             output_file  # è¾“å‡ºæ–‡ä»¶è·¯å¾„
#         ]

#         try:
#             subprocess.run(
#                 cmd,
#                 check=True,
#                 stdout=subprocess.PIPE,
#                 stderr=subprocess.PIPE,
#                 encoding='utf-8'
#             )
#         except subprocess.CalledProcessError as e:
#             print(f"éŸ³é¢‘æå–å¤±è´¥ï¼š{e.stderr}")
#             raise Exception(f"ffmpegæå–éŸ³é¢‘å¤±è´¥ï¼š{e.stderr}")

#         if not os.path.exists(output_file) or os.path.getsize(output_file) == 0:
#             raise Exception(f"éŸ³é¢‘åˆ‡ç‰‡æ–‡ä»¶ç”Ÿæˆå¤±è´¥ï¼š{output_file}")


#     def merge_short_segments(self):
#         if not self.short_segments_cache:
#             return
        
#         merged_start = self.short_segments_cache[0]["start"]
#         merged_end = self.short_segments_cache[-1]["end"]
#         merged_text = "".join([seg["text"] for seg in self.short_segments_cache])
        
#         start_str = self.format_srt_time(merged_start)
#         end_str = self.format_srt_time(merged_end)
        
#         with open(self.srt_path, "a", encoding="utf-8") as f:
#             f.write(f"{self.subtitle_index}\n")
#             f.write(f"{start_str} --> {end_str}\n")
#             f.write(f"{merged_text}\n\n")
        
#         self.subtitle_updated.emit(merged_start,merged_end,merged_text)
#         self.subtitle_index += 1
        
#         self.short_segments_cache = []

#     def run(self):
#         try:
#             self.preload_model()

#             if not self.total_duration or self.total_duration <= 0:
#                 raise Exception("æ— æ³•è·å–è§†é¢‘æ—¶é•¿")

#             with open(self.srt_path, "w", encoding="utf-8") as f:
#                 f.write("")

#             current_time = 0
#             self.progress.emit("å¼€å§‹å®æ—¶ç”Ÿæˆå­—å¹•...", 10)
            
#             # è®¡ç®—æ€»åˆ‡ç‰‡æ•°
#             total_slices = int(self.total_duration / self.slice_duration) + 1
            
#             # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦æ¡ï¼ˆåŒæ—¶æŒ‡å®šfileå’Œpositioné¿å…é‡å¤ï¼‰
#             with tqdm(total=total_slices, desc="å­—å¹•ç”Ÿæˆ", unit="åˆ‡ç‰‡", ncols=100, file=sys.stdout, position=0) as pbar:
#                 while current_time < self.total_duration and self.is_running:
#                     # è®¡ç®—å½“å‰è¿›åº¦
#                     progress_percent = int(10 + (current_time / self.total_duration) * 90)
#                     self.progress.emit(f"æ­£åœ¨è¯†åˆ« {current_time:.1f} - {current_time + self.slice_duration:.1f} ç§’...", progress_percent)

#                     # åˆ›å»ºä¸´æ—¶éŸ³é¢‘åˆ‡ç‰‡æ–‡ä»¶
#                     temp_fd, temp_audio = tempfile.mkstemp(suffix=".wav")
#                     os.close(temp_fd)  # å…³é—­æ–‡ä»¶æè¿°ç¬¦
#                     self.temp_files.append(temp_audio)

#                     # æå–å½“å‰æ—¶é—´æ®µçš„éŸ³é¢‘åˆ‡ç‰‡
#                     self.extract_audio_slice(current_time, self.slice_duration, temp_audio)

#                     # æ£€æŸ¥åˆ‡ç‰‡æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
#                     if not os.path.exists(temp_audio) or os.path.getsize(temp_audio) == 0:
#                         current_time += self.slice_duration
#                         continue

#                     #è¯†åˆ«åˆ‡ç‰‡éŸ³é¢‘
#                     # result = self.model.transcribe(
#                     #     temp_audio,
#                     #     language="zh",
#                     #     verbose=None,  # ä½¿ç”¨Noneå®Œå…¨ç¦ç”¨è¾“å‡º
#                     #     fp16=False,
#                     #     no_speech_threshold=0.1
#                     # )
#                     res = self.asr_client.transcribe(
#                         file_path=temp_audio,
#                         model="TeleAI/TeleSpeechASR"
#                     )
#                     #ä¹‹å‰å†™æ­»å¼ºåˆ¶ä»¥slice_durationä¸ºå­—å¹•èµ·æ­¢æ—¶é—´é—´éš”
#                     # è§£æè¯†åˆ«ç»“æœå¹¶å¤„ç†çŸ­ç‰‡æ®µåˆå¹¶
#                     if result["segments"]:
#                         for seg in result["segments"]:
#                             # ä¿®æ­£å­—å¹•æ—¶é—´ï¼ˆåŸºäºåˆ‡ç‰‡èµ·å§‹æ—¶é—´ï¼‰
#                             seg_start = current_time + seg["start"]
#                             seg_end = current_time + seg["end"]
#                             seg_duration = seg_end - seg_start
#                             # ç¹è½¬ç®€
#                             subtitle_text = self.converter.convert(seg["text"].strip())

#                             # åˆ¤æ–­æ˜¯å¦ä¸ºçŸ­ç‰‡æ®µ
#                             if seg_duration < self.short_segment_threshold:
#                                 # åŠ å…¥ç¼“å­˜
#                                 self.short_segments_cache.append({
#                                     "start": seg_start,
#                                     "end": seg_end,
#                                     "text": subtitle_text
#                                 })
#                             else:
#                                 # å…ˆåˆå¹¶ç¼“å­˜ä¸­çš„çŸ­ç‰‡æ®µ
#                                 self.merge_short_segments()
#                                 # ç›´æ¥å†™å…¥é•¿ç‰‡æ®µ
#                                 start_str = self.format_srt_time(seg_start)
#                                 end_str = self.format_srt_time(seg_end)
#                                 with open(self.srt_path, "a", encoding="utf-8") as f:
#                                     f.write(f"{self.subtitle_index}\n")
#                                     f.write(f"{start_str} --> {end_str}\n")
#                                     f.write(f"{subtitle_text}\n\n")
#                                 self.subtitle_updated.emit(seg_start,seg_end,subtitle_text)
#                                 self.subtitle_index += 1

#                     # åˆ‡ç‰‡ç»“æŸæ—¶ï¼Œåˆå¹¶å‰©ä½™çš„çŸ­ç‰‡æ®µ
#                     self.merge_short_segments()
#                     # æ¨è¿›æ—¶é—´è½´
#                     current_time += self.slice_duration
#                     time.sleep(0.1)
                        
#                     # æ›´æ–°è¿›åº¦æ¡
#                     pbar.update(1)
#                     pbar.set_postfix_str(f"æ—¶é—´: {current_time:.1f}s")

#                 # æœ€ç»ˆåˆå¹¶æ‰€æœ‰å‰©ä½™çš„çŸ­ç‰‡æ®µ
#                 self.merge_short_segments()

#                 if self.is_running:
#                     self.progress.emit("å®æ—¶å­—å¹•ç”Ÿæˆå®Œæˆï¼", 100)
#                     self.finished.emit(True, f"å®æ—¶å­—å¹•å·²ä¿å­˜ï¼š{os.path.basename(self.srt_path)}")
#                 else:
#                     self.finished.emit(False, "ç”¨æˆ·ç»ˆæ­¢äº†å®æ—¶å­—å¹•ç”Ÿæˆ")

#         except Exception as e:
#             self.finished.emit(False, f"å®æ—¶å­—å¹•ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")
#         finally:
#             clean_temp(self.temp_files)

#     def format_srt_time(self, seconds):
#         """å°†ç§’æ•°è½¬æ¢ä¸ºSRTæ ‡å‡†æ—¶é—´æ ¼å¼ï¼ˆ00:00:00,000ï¼‰"""
#         td = timedelta(seconds=seconds)
#         hours, remainder = divmod(td.seconds, 3600)
#         minutes, secs = divmod(remainder, 60)
#         milliseconds = td.microseconds // 1000
#         return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"

#     def stop(self):
#         self.is_running = False

#åŸºäºfunasrçš„ä¸åˆ‡ç‰‡å­—å¹•ç”Ÿæˆ
# import os,re
# import sys
# import time
# import tempfile
# from PySide6.QtCore import QObject, Signal
# from datetime import timedelta
# import whisper
# from opencc import OpenCC
# import subprocess
# from tqdm import tqdm
# from funasr import AutoModel

# # å­—å¹•ç”Ÿæˆ
# # éŸ³é¢‘ä¸åˆ‡ç‰‡
# def clean_temp(files):

#     for file in files:
#         if os.path.exists(file):
#             try:
#                 os.remove(file)
#             except Exception as e:
#                 print(f"è­¦å‘Šï¼šæ— æ³•åˆ é™¤ä¸´æ—¶æ–‡ä»¶ {file}: {e}")


# class SubtitleWorker(QObject):
#     progress = Signal(str, int)
#     finished = Signal(bool, str)

#     def __init__(self,model, video_path, srt_path):
#         super().__init__()
#         self.video_path = video_path
#         self.srt_path = srt_path
#         self.is_running = True
#         self.converter=OpenCC('t2s')
#         self.model=model
#     def run(self):
#         audio_temp = "temp_audio.wav"
#         try:
#             self.progress.emit("æ­£åœ¨æå–éŸ³é¢‘...", 20)
#             # æå–éŸ³é¢‘
#             os.system(f'ffmpeg -i "{self.video_path}" -vn -acodec pcm_s16le -ar 16000 -ac 1 "{audio_temp}"')
#             # æ£€æµ‹éŸ³é¢‘ä¸´æ—¶æ–‡ä»¶æ˜¯å¦ç”Ÿæˆï¼Œä¸”æœ‰æ•°æ®å†™å…¥
#             if not self.is_running or not os.path.exists(audio_temp) or os.path.getsize(audio_temp) == 0:
#                 raise Exception("éŸ³é¢‘æå–å¤±è´¥æˆ–ç”¨æˆ·å–æ¶ˆæ“ä½œ")

#             self.progress.emit(f"æ­£åœ¨ä½¿ç”¨ funasr æ¨¡å‹è¯†åˆ«...", 40)

#             self.audio_to_subtitle(self.model,audio_temp,self.srt_path)
#             if not self.is_running:
#                 raise Exception("ç”¨æˆ·å–æ¶ˆäº†ç”Ÿæˆ")

#             self.progress.emit("æ­£åœ¨è§£æå¹¶ä¿å­˜å­—å¹•...", 80)
        
#             # æç¤ºå­—å¹•ç”Ÿæˆå®Œæˆ
#             self.progress.emit("å­—å¹•ç”Ÿæˆå®Œæˆï¼", 100)
#             self.finished.emit(True, f"å­—å¹•å·²ä¿å­˜ä¸ºSRTæ–‡ä»¶ï¼š{os.path.basename(self.srt_path)}")

#         except Exception as e:
#             self.finished.emit(False, f"å­—å¹•ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")
#         finally:
#             clean_temp([audio_temp])

#     def format_time(self,seconds):
#         """å°†ç§’æ•°æ ¼å¼åŒ–ä¸º SRT å­—å¹•æ—¶é—´æ ¼å¼: 00:00:00,000"""
#         hours = int(seconds // 3600)
#         minutes = int((seconds % 3600) // 60)
#         secs = int(seconds % 60)
#         ms = int((seconds - int(seconds)) * 1000)
#         return f"{hours:02d}:{minutes:02d}:{secs:02d},{ms:03d}"

#     def split_text_by_punctuation(self,text, split_chars=None):
#         """æŒ‰æ ‡ç‚¹æ‹†åˆ†æ–‡æœ¬ï¼Œé€‚é…æ—¶é—´æˆ³åˆ†æ®µ"""
#         if split_chars is None:
#             split_chars = r'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€.?!;:'
#         parts = re.split(f'([{split_chars}])', text)
#         merged_parts = []
#         temp = ""
#         for part in parts:
#             if part:
#                 temp += part
#                 if part in split_chars:
#                     merged_parts.append(temp.strip())
#                     temp = ""
#         if temp:
#             merged_parts.append(temp.strip())
#         return merged_parts

#     # ==================== å¤ç”¨æ¨¡å‹ç”Ÿæˆå­—å¹• ====================
#     def audio_to_subtitle(self,preloaded_model, audio_path, output_srt_path=None):

#         # è®¾ç½®é»˜è®¤è¾“å‡ºè·¯å¾„
#         if output_srt_path is None:
#             base_name = os.path.splitext(audio_path)[0]
#             output_srt_path = f"{base_name}.srt"
        
#         # å¤ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†ï¼ˆæ— éœ€é‡æ–°åŠ è½½ï¼‰
#         print(f"\næ­£åœ¨å¤„ç†éŸ³é¢‘: {audio_path}")
#         res = preloaded_model.generate(
#             input=audio_path,
#             batch_size_s=30,
#             merge_vad=True,
#             use_itn=True,
#             add_pause=True,
#             predict_timestamp=True
#         )
        
#         srt_content = []
#         index = 1
#         try:
#             full_text = res[0].get("text", "").strip()
#             timestamps_ms = res[0].get("timestamp", [])
            
#             if not full_text or not timestamps_ms:
#                 raise ValueError("æœªè·å–åˆ°æœ‰æ•ˆæ–‡æœ¬æˆ–æ—¶é—´æˆ³")
            
#             # æ‹†åˆ†æ–‡æœ¬ + åŒ¹é…æ—¶é—´æˆ³
#             text_segments = self.split_text_by_punctuation(full_text)
#             # é€‚é…æ–‡æœ¬å’Œæ—¶é—´æˆ³æ•°é‡
#             if len(text_segments) > len(timestamps_ms):
#                 text_segments = text_segments[:len(timestamps_ms)]
#             elif len(text_segments) < len(timestamps_ms):
#                 ts_per_segment = len(timestamps_ms) // len(text_segments)
#                 remainder = len(timestamps_ms) % len(text_segments)
#                 new_timestamps = []
#                 current = 0
#                 for i in range(len(text_segments)):
#                     count = ts_per_segment + (1 if i < remainder else 0)
#                     count = min(count, len(timestamps_ms) - current)
#                     start_ms = timestamps_ms[current][0]
#                     end_ms = timestamps_ms[current + count - 1][1]
#                     new_timestamps.append([start_ms, end_ms])
#                     current += count
#                 timestamps_ms = new_timestamps
            
#             # ç”Ÿæˆå­—å¹•ç‰‡æ®µ
#             for i in range(min(len(text_segments), len(timestamps_ms))):
#                 start_ms, end_ms = timestamps_ms[i]
#                 start_time = start_ms / 1000.0
#                 end_time = end_ms / 1000.0
#                 text = text_segments[i]
                
#                 if not text or start_time >= end_time:
#                     continue
                
#                 start_str = self.format_time(start_time)
#                 end_str = self.format_time(end_time)
#                 srt_content.extend([str(index), f"{start_str} --> {end_str}", text.strip(), ""])
#                 index += 1
            
#             if index == 1:
#                 raise ValueError("æœªç”Ÿæˆæœ‰æ•ˆå­—å¹•ç‰‡æ®µ")
        
#         except Exception as e:
#             print(f"âš ï¸ è§£æå¤±è´¥: {e}ï¼Œå¯ç”¨å…œåº•æ–¹æ¡ˆ")
#             full_text = res[0].get("text", "").strip()
#             if full_text:
#                 srt_content = ["1", "00:00:00,000 --> 00:30:00,000", full_text, ""]
        
#         # å†™å…¥æ–‡ä»¶
#         with open(output_srt_path, "w", encoding="utf-8") as f:
#             f.write("\n".join(srt_content))
#         print(f"âœ… å­—å¹•ç”Ÿæˆå®Œæˆ: {output_srt_path}")
#         print(f"ğŸ“ å…±ç”Ÿæˆ {max(index-1, 1)} æ¡å­—å¹•")

#     def stop(self):
#         self.is_running = False


import os
import re
import sys
import time
import tempfile
from PySide6.QtCore import QObject, Signal
from datetime import timedelta
import subprocess
from tqdm import tqdm
from opencc import OpenCC
from funasr import AutoModel

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶å·¥å…·å‡½æ•°
def clean_temp(files):
    for file in files:
        if os.path.exists(file):
            try:
                os.remove(file)
            except Exception as e:
                print(f"è­¦å‘Šï¼šæ— æ³•åˆ é™¤ä¸´æ—¶æ–‡ä»¶ {file}: {e}")

# åˆ†ç‰‡è¯†åˆ«çš„å­—å¹•ç”Ÿæˆçº¿ç¨‹ï¼ˆå¯¹é½Whisperåˆ†ç‰‡é€»è¾‘ï¼‰
class SubtitleWorker(QObject):
    progress = Signal(str, int)
    finished = Signal(bool, str)
    subtitle_updated = Signal(float, float, str)  # æ–°å¢ï¼šå®æ—¶æ›´æ–°å•æ¡å­—å¹•ä¿¡å·

    def __init__(self, model,player_core, video_path, srt_path, total_duration, slice_duration=10, short_segment_threshold=2.0):
        super().__init__()
        self.model = model  # é¢„åŠ è½½çš„FunASRæ¨¡å‹
        self.player_core = player_core  # ä¼ å…¥çš„æ’­æ”¾å™¨æ ¸å¿ƒå¯¹è±¡
        self.video_path = video_path
        self.srt_path = srt_path  # ä¿®å¤åŸä»£ç çš„å…ƒç»„é—®é¢˜ï¼ˆåŸä»£ç å¤šäº†ä¸ªé€—å·ï¼‰
        self.total_duration = total_duration  # è§†é¢‘æ€»æ—¶é•¿
        self.slice_duration = slice_duration  # éŸ³é¢‘åˆ‡ç‰‡æ—¶é•¿ï¼ˆé»˜è®¤10ç§’ï¼‰
        self.short_segment_threshold = short_segment_threshold  # çŸ­ç‰‡æ®µåˆå¹¶é˜ˆå€¼ï¼ˆé»˜è®¤2ç§’ï¼‰
        self.is_running = True
        self.converter = OpenCC('t2s')  # ç¹è½¬ç®€
        self.subtitle_index = 1  # å­—å¹•åºå·
        self.temp_files = []  # ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶ç¼“å­˜
        self.short_segments_cache = []  # çŸ­ç‰‡æ®µç¼“å­˜ï¼ˆç”¨äºåˆå¹¶ï¼‰

    # æå–æŒ‡å®šæ—¶é—´æ®µçš„éŸ³é¢‘åˆ‡ç‰‡ï¼ˆå¤ç”¨åŸWhisperçš„ffmpegé€»è¾‘ï¼Œä¿è¯åˆ‡ç‰‡æ ¼å¼ç»Ÿä¸€ï¼‰
    def extract_audio_slice(self, start_time, duration, output_file):
        cmd = [
            'ffmpeg',
            '-y',  # è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶
            '-ss', f'{start_time:.2f}',  # èµ·å§‹æ—¶é—´
            '-i', self.video_path,  # è¾“å…¥è§†é¢‘æ–‡ä»¶
            '-t', f'{duration:.2f}',  # æå–æ—¶é•¿
            '-vn',  # ç¦ç”¨è§†é¢‘æµ
            '-acodec', 'pcm_s16le',  # éŸ³é¢‘ç¼–ç 
            '-ar', '16000',  # é‡‡æ ·ç‡
            '-ac', '1',  # å•å£°é“
            '-f', 'wav',  # è¾“å‡ºæ ¼å¼
            '-hide_banner',  # éšè—bannerä¿¡æ¯
            '-loglevel', 'error',  # ä»…è¾“å‡ºé”™è¯¯ä¿¡æ¯
            output_file  # è¾“å‡ºæ–‡ä»¶è·¯å¾„
        ]

        try:
            subprocess.run(
                cmd,
                check=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                encoding='utf-8'
            )
        except subprocess.CalledProcessError as e:
            print(f"éŸ³é¢‘æå–å¤±è´¥ï¼š{e.stderr}")
            raise Exception(f"ffmpegæå–éŸ³é¢‘å¤±è´¥ï¼š{e.stderr}")

        if not os.path.exists(output_file) or os.path.getsize(output_file) == 0:
            raise Exception(f"éŸ³é¢‘åˆ‡ç‰‡æ–‡ä»¶ç”Ÿæˆå¤±è´¥ï¼š{output_file}")

    # åˆå¹¶çŸ­ç‰‡æ®µï¼ˆæ ¸å¿ƒé€»è¾‘å¤ç”¨Whisperç‰ˆæœ¬ï¼‰
    def merge_short_segments(self):
        if not self.short_segments_cache:
            return
        
        merged_start = self.short_segments_cache[0]["start"]
        merged_end = self.short_segments_cache[-1]["end"]
        merged_text = "".join([seg["text"] for seg in self.short_segments_cache])
        
        start_str = self.format_srt_time(merged_start)
        end_str = self.format_srt_time(merged_end)
        
        with open(self.srt_path, "a", encoding="utf-8") as f:
            f.write(f"{self.subtitle_index}\n")
            f.write(f"{start_str} --> {end_str}\n")
            f.write(f"{merged_text}\n\n")
        
        self.subtitle_updated.emit(merged_start, merged_end, merged_text)
        self.player_core.inject_mpv_subtitle(merged_start, merged_end, merged_text, 1)
        self.subtitle_index += 1
        self.short_segments_cache = []

    # æ ¼å¼åŒ–SRTæ—¶é—´ï¼ˆå¤ç”¨åŸé€»è¾‘ï¼‰
    def format_srt_time(self, seconds):
        td = timedelta(seconds=seconds)
        hours, remainder = divmod(td.seconds, 3600)
        minutes, secs = divmod(remainder, 60)
        milliseconds = td.microseconds // 1000
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"

    # å•åˆ‡ç‰‡éŸ³é¢‘è½¬å­—å¹•ï¼ˆé€‚é…FunASRçš„è¯†åˆ«é€»è¾‘ï¼‰
    def slice_audio_to_subtitle(self, audio_path, slice_start_time):
        """
        è¯†åˆ«å•åˆ‡ç‰‡éŸ³é¢‘ï¼Œè¿”å›å¸¦æ—¶é—´åç§»çš„å­—å¹•ç‰‡æ®µ
        :param audio_path: åˆ‡ç‰‡éŸ³é¢‘è·¯å¾„
        :param slice_start_time: åˆ‡ç‰‡åœ¨åŸè§†é¢‘ä¸­çš„èµ·å§‹æ—¶é—´ï¼ˆç§’ï¼‰
        :return: å­—å¹•ç‰‡æ®µåˆ—è¡¨ [{"start": ç»å¯¹å¼€å§‹æ—¶é—´, "end": ç»å¯¹ç»“æŸæ—¶é—´, "text": æ–‡æœ¬}, ...]
        """
        # è°ƒç”¨FunASRè¯†åˆ«åˆ‡ç‰‡éŸ³é¢‘
        res = self.model.generate(
            input=audio_path,
            batch_size_s=30,
            merge_vad=True,
            use_itn=True,
            add_pause=True,
            predict_timestamp=True
        )

        segments = []
        try:
            full_text = res[0].get("text", "").strip()
            timestamps_ms = res[0].get("timestamp", [])
            
            if not full_text or not timestamps_ms:
                return segments
            
            # æŒ‰æ ‡ç‚¹æ‹†åˆ†æ–‡æœ¬ï¼ˆå¤ç”¨åŸFunASRç‰ˆæœ¬çš„æ‹†åˆ†é€»è¾‘ï¼‰
            text_segments = self.split_text_by_punctuation(full_text)
            
            # é€‚é…æ–‡æœ¬å’Œæ—¶é—´æˆ³æ•°é‡ï¼ˆå¤ç”¨åŸé€»è¾‘ï¼‰
            if len(text_segments) > len(timestamps_ms):
                text_segments = text_segments[:len(timestamps_ms)]
            elif len(text_segments) < len(timestamps_ms):
                ts_per_segment = len(timestamps_ms) // len(text_segments)
                remainder = len(timestamps_ms) % len(text_segments)
                new_timestamps = []
                current = 0
                for i in range(len(text_segments)):
                    count = ts_per_segment + (1 if i < remainder else 0)
                    count = min(count, len(timestamps_ms) - current)
                    start_ms = timestamps_ms[current][0]
                    end_ms = timestamps_ms[current + count - 1][1]
                    new_timestamps.append([start_ms, end_ms])
                    current += count
                timestamps_ms = new_timestamps
            
            # è½¬æ¢ä¸ºç»å¯¹æ—¶é—´ï¼ˆåˆ‡ç‰‡èµ·å§‹æ—¶é—´ + åˆ‡ç‰‡å†…ç›¸å¯¹æ—¶é—´ï¼‰
            for i in range(min(len(text_segments), len(timestamps_ms))):
                start_ms, end_ms = timestamps_ms[i]
                # åˆ‡ç‰‡å†…ç›¸å¯¹æ—¶é—´è½¬ç§’ + åˆ‡ç‰‡èµ·å§‹æ—¶é—´ = ç»å¯¹æ—¶é—´
                seg_start = slice_start_time + (start_ms / 1000.0)
                seg_end = slice_start_time + (end_ms / 1000.0)
                text = self.converter.convert(text_segments[i].strip())  # ç¹è½¬ç®€
                
                if text and seg_start < seg_end:
                    segments.append({
                        "start": seg_start,
                        "end": seg_end,
                        "text": text
                    })
        except Exception as e:
            print(f"åˆ‡ç‰‡è¯†åˆ«å¤±è´¥ï¼ˆå…œåº•å¤„ç†ï¼‰ï¼š{e}")
            # å…œåº•ï¼šç»™åˆ‡ç‰‡ä¸€ä¸ªé»˜è®¤çš„æ•´æ®µå­—å¹•
            full_text = res[0].get("text", "").strip() if res else ""
            if full_text:
                segments.append({
                    "start": slice_start_time,
                    "end": slice_start_time + self.slice_duration,
                    "text": self.converter.convert(full_text)
                })
        return segments

    # æŒ‰æ ‡ç‚¹æ‹†åˆ†æ–‡æœ¬ï¼ˆå¤ç”¨åŸFunASRç‰ˆæœ¬ï¼‰
    def split_text_by_punctuation(self, text, split_chars=None):
        if split_chars is None:
            split_chars = r'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€.?!;:'
        parts = re.split(f'([{split_chars}])', text)
        merged_parts = []
        temp = ""
        for part in parts:
            if part:
                temp += part
                if part in split_chars:
                    merged_parts.append(temp.strip())
                    temp = ""
        if temp:
            merged_parts.append(temp.strip())
        return merged_parts

    # æ ¸å¿ƒè¿è¡Œé€»è¾‘ï¼ˆåˆ†ç‰‡è¯†åˆ«ï¼‰
    def run(self):
        try:
            if not self.total_duration or self.total_duration <= 0:
                raise Exception("æ— æ³•è·å–è§†é¢‘æ—¶é•¿")

            # æ¸…ç©ºSRTæ–‡ä»¶ï¼ˆåˆå§‹åŒ–ï¼‰
            with open(self.srt_path, "w", encoding="utf-8") as f:
                f.write("")

            current_time = 0  # å½“å‰åˆ‡ç‰‡èµ·å§‹æ—¶é—´
            self.progress.emit("å¼€å§‹åˆ†ç‰‡ç”Ÿæˆå­—å¹•...", 10)
            
            total_slices = int(self.total_duration / self.slice_duration) + 1
            
            with tqdm(total=total_slices, desc="å­—å¹•ç”Ÿæˆ", unit="åˆ‡ç‰‡", ncols=100, file=sys.stdout, position=0) as pbar:
                while current_time < self.total_duration and self.is_running:
                    # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”
                    progress_percent = int(10 + (current_time / self.total_duration) * 90)
                    self.progress.emit(
                        f"æ­£åœ¨è¯†åˆ« {current_time:.1f} - {current_time + self.slice_duration:.1f} ç§’...", 
                        progress_percent
                    )

                    # åˆ›å»ºä¸´æ—¶éŸ³é¢‘åˆ‡ç‰‡æ–‡ä»¶
                    temp_fd, temp_audio = tempfile.mkstemp(suffix=".wav")
                    os.close(temp_fd)
                    self.temp_files.append(temp_audio)

                    # æå–å½“å‰åˆ‡ç‰‡çš„éŸ³é¢‘
                    self.extract_audio_slice(current_time, self.slice_duration, temp_audio)

                    # è¯†åˆ«å½“å‰åˆ‡ç‰‡éŸ³é¢‘
                    slice_segments = self.slice_audio_to_subtitle(temp_audio, current_time)



                    # å¤„ç†è¯†åˆ«ç»“æœï¼ˆçŸ­ç‰‡æ®µåˆå¹¶é€»è¾‘å¯¹é½Whisperç‰ˆæœ¬ï¼‰
                    for seg in slice_segments:
                        seg_duration = seg["end"] - seg["start"]
                        # çŸ­ç‰‡æ®µï¼šåŠ å…¥ç¼“å­˜
                        if seg_duration < self.short_segment_threshold:
                            self.short_segments_cache.append(seg)
                        # é•¿ç‰‡æ®µï¼šå…ˆåˆå¹¶ç¼“å­˜ï¼Œå†å†™å…¥å½“å‰ç‰‡æ®µ
                        else:
                            self.merge_short_segments()
                            start_str = self.format_srt_time(seg["start"])
                            end_str = self.format_srt_time(seg["end"])
                            with open(self.srt_path, "a", encoding="utf-8") as f:
                                f.write(f"{self.subtitle_index}\n")
                                f.write(f"{start_str} --> {end_str}\n")
                                f.write(f"{seg['text']}\n\n")
                            self.subtitle_updated.emit(seg["start"], seg["end"], seg["text"])
                            self.player_core.inject_mpv_subtitle(seg["start"], seg["end"], seg["text"], 1)
                            self.subtitle_index += 1
                            

                    # åˆ‡ç‰‡å¤„ç†å®Œåï¼Œåˆå¹¶ç¼“å­˜ä¸­çš„çŸ­ç‰‡æ®µ
                    self.merge_short_segments()

                    # æ¨è¿›æ—¶é—´è½´
                    current_time += self.slice_duration
                    time.sleep(0.1)
                    
                    # æ›´æ–°è¿›åº¦æ¡
                    pbar.update(1)
                    pbar.set_postfix_str(f"æ—¶é—´: {current_time:.1f}s")

                # æœ€ç»ˆåˆå¹¶æ‰€æœ‰å‰©ä½™çš„çŸ­ç‰‡æ®µ
                self.merge_short_segments()

                if self.is_running:
                    self.progress.emit("åˆ†ç‰‡å­—å¹•ç”Ÿæˆå®Œæˆï¼", 100)
                    self.finished.emit(True, f"å­—å¹•å·²ä¿å­˜ï¼š{os.path.basename(self.srt_path)}")
                else:
                    self.finished.emit(False, "ç”¨æˆ·ç»ˆæ­¢äº†å­—å¹•ç”Ÿæˆ")

        except Exception as e:
            self.finished.emit(False, f"å­—å¹•ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            clean_temp(self.temp_files)

    # åœæ­¢çº¿ç¨‹
    def stop(self):
        self.is_running = False