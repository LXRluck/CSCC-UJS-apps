from funasr import AutoModel
import re
import os

print("æ­£åœ¨é¢„å…ˆåŠ è½½æ¨¡å‹...ï¼ˆé¦–æ¬¡è¿è¡Œè€—æ—¶è¾ƒé•¿ï¼Œåç»­å¤ç”¨æ— éœ€é‡å¤åŠ è½½ï¼‰")
model = AutoModel(
    model="paraformer-zh",
    vad_model="fsmn-vad",
    punc_model="ct-punc",
    disable_update=True,
    device="cpu",
    model_revision="v2.0.4"
)
print("âœ… æ¨¡å‹é¢„å…ˆåŠ è½½å®Œæˆï¼")

# ==================== å·¥å…·å‡½æ•° ====================
def format_time(seconds):
    """å°†ç§’æ•°æ ¼å¼åŒ–ä¸º SRT å­—å¹•æ—¶é—´æ ¼å¼: 00:00:00,000"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    ms = int((seconds - int(seconds)) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{ms:03d}"

def split_text_by_punctuation(text, split_chars=None):
    """æŒ‰æ ‡ç‚¹æ‹†åˆ†æ–‡æœ¬ï¼Œé€‚é…æ—¶é—´æˆ³åˆ†æ®µ"""
    if split_chars is None:
        split_chars = r'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€.?!;:'
    parts = re.split(f'([{split_chars}])', text)
    merged_parts = []
    temp = ""
    for part in parts:
        if part:
            temp += part
            if part in split_chars:
                merged_parts.append(temp.strip())
                temp = ""
    if temp:
        merged_parts.append(temp.strip())
    return merged_parts

# ==================== å¤ç”¨æ¨¡å‹ç”Ÿæˆå­—å¹• ====================
def audio_to_subtitle(preloaded_model, audio_path, output_srt_path=None):

    # è®¾ç½®é»˜è®¤è¾“å‡ºè·¯å¾„
    if output_srt_path is None:
        base_name = os.path.splitext(audio_path)[0]
        output_srt_path = f"{base_name}.srt"
    
    # å¤ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†ï¼ˆæ— éœ€é‡æ–°åŠ è½½ï¼‰
    print(f"\næ­£åœ¨å¤„ç†éŸ³é¢‘: {audio_path}")
    res = preloaded_model.generate(
        input=audio_path,
        batch_size_s=30,
        merge_vad=True,
        use_itn=True,
        add_pause=True,
        predict_timestamp=True
    )
    
    srt_content = []
    index = 1
    try:
        full_text = res[0].get("text", "").strip()
        timestamps_ms = res[0].get("timestamp", [])
        
        if not full_text or not timestamps_ms:
            raise ValueError("æœªè·å–åˆ°æœ‰æ•ˆæ–‡æœ¬æˆ–æ—¶é—´æˆ³")
        
        # æ‹†åˆ†æ–‡æœ¬ + åŒ¹é…æ—¶é—´æˆ³
        text_segments = split_text_by_punctuation(full_text)
        # é€‚é…æ–‡æœ¬å’Œæ—¶é—´æˆ³æ•°é‡
        if len(text_segments) > len(timestamps_ms):
            text_segments = text_segments[:len(timestamps_ms)]
        elif len(text_segments) < len(timestamps_ms):
            ts_per_segment = len(timestamps_ms) // len(text_segments)
            remainder = len(timestamps_ms) % len(text_segments)
            new_timestamps = []
            current = 0
            for i in range(len(text_segments)):
                count = ts_per_segment + (1 if i < remainder else 0)
                count = min(count, len(timestamps_ms) - current)
                start_ms = timestamps_ms[current][0]
                end_ms = timestamps_ms[current + count - 1][1]
                new_timestamps.append([start_ms, end_ms])
                current += count
            timestamps_ms = new_timestamps
        
        # ç”Ÿæˆå­—å¹•ç‰‡æ®µ
        for i in range(min(len(text_segments), len(timestamps_ms))):
            start_ms, end_ms = timestamps_ms[i]
            start_time = start_ms / 1000.0
            end_time = end_ms / 1000.0
            text = text_segments[i]
            
            if not text or start_time >= end_time:
                continue
            
            start_str = format_time(start_time)
            end_str = format_time(end_time)
            srt_content.extend([str(index), f"{start_str} --> {end_str}", text.strip(), ""])
            index += 1
        
        if index == 1:
            raise ValueError("æœªç”Ÿæˆæœ‰æ•ˆå­—å¹•ç‰‡æ®µ")
    
    except Exception as e:
        print(f"âš ï¸ è§£æå¤±è´¥: {e}ï¼Œå¯ç”¨å…œåº•æ–¹æ¡ˆ")
        full_text = res[0].get("text", "").strip()
        if full_text:
            srt_content = ["1", "00:00:00,000 --> 00:30:00,000", full_text, ""]
    
    # å†™å…¥æ–‡ä»¶
    with open(output_srt_path, "w", encoding="utf-8") as f:
        f.write("\n".join(srt_content))
    print(f"âœ… å­—å¹•ç”Ÿæˆå®Œæˆ: {output_srt_path}")
    print(f"ğŸ“ å…±ç”Ÿæˆ {max(index-1, 1)} æ¡å­—å¹•")


# ç¤ºä¾‹ä½¿ç”¨
if __name__ == "__main__":
    # æ›¿æ¢ä¸ºä½ çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    audio_file = r"D:\video\base_test.mp3"  # æ”¯æŒ wav, mp3, m4a ç­‰æ ¼å¼
    
    # ç”Ÿæˆå­—å¹•
    audio_to_subtitle(model,audio_file,r"D:\video\base_test.srt")